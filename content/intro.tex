\chapter{Introduction}
\label{cha:introduction}

% One of the most significant achievements in the 21st century is artificial intelligence (AI), especially machine learning (ML), which relies on using powerful computer hardware to accumulate and analyze massive data to improve the performance of algorithms. On the one hand, the customers enjoy the convenient services driven by ML algorithms. On the other hand, the users' sensitive data might be revealed to the third-party untrusted service provider. Even if the service providers are not malicious, other malicious entities such as internal employees, hackers, and national intelligence agencies could abuse the centralized database. Therefore, it is urgent to protect users' privacy while providing services. Since 2008, cryptographers have proposed many privacy-preserving ML algorithms based on secure multi-party computation (MPC). Secure multi-party computation enables multiple parties to perform computations with parties' inputs securely such that only the computation result is revealed. Secure multi-party computation is first proposed by Yao~\cite{Yao86} and becomes efficient for practical deployment until the late 2000s.

% Consider a typical scenario of privacy-preserving ML: Alice wishes to detect if she has the genetic disease but keep her genomic data secret. As a service provider, Bob has trained an ML model that can predict genetic disease when given genomic data. Similarly, Bob also wishes to keep the ML model parameters private to profit from it continuously. One solution is introducing a trusted third party to do genome sequencing with Alice's genomic data and Bob's ML model. However, a trusted third party barely exists in practice. Instead, Alice and Bob can deploy MPC protocol to solve the problem by simulating a trusted third party such that only the gene detection result is revealed.

% Although MPC can guarantee the users' computational privacy, an adversary can still infer users' sensitive information from the computation result by executing attacks such as membership inference. For example, several hospitals jointly trained an ML model using MPC protocols with their patient's data, and only the trained ML model parameters were revealed to them. An adversary doesn't have access to the patients' data but can still infer if a particular patient's data is involved in the ML training and further derive additional sensitive information. Dwork et al.~\cite{dwork2006differential} formalize this privacy loss by introducing the concept of differential privacy (DP). One approach to guarantee DP is to add calibrated noise to the revealed computation result~\cite{dwork2006differential, dwork2006calibrating}.

% Naturally, a better privacy-preserving method is to combine MPC and DP as prior works~\cite{eigner2014differentially,byrd2020differentially,pettai2015combining}. However, as far as we know, no prior works have considered the security issues under practical implementations. As Mironov~\cite{mironov2012significance} shows, the textbook noise generation methods can breach differential privacy under floating-point arithemtic. Our work attempts to fill the vacuum by providing efficient and secure MPC-DP protocols and implementations.

% \textbf{Research Goal}
% In this thesis, we study how to achieve DP under MPC setting securely, i.e., constructing MPC protocols for secure noise generation and output perturbation. In addition, we aim at efficient MPC protocols by evaluating various optimization techniques and their practical performance.

% \textbf{Contributions}
% We invest the secure noise generation methods and prove that these noise under floating-point number representation can satisfy the differential privacy. A major part of this thesis deals with the construction and optimizations of MPC protocols for noise generation as MPC is still significantly slower than plaintext computations. Specifically, we consider the outsourcing scenario of MPC, i.e., users first secret share their private input to multiple ($N \geq 2$) non-colluding computing parties and the computing parties execute the MPC protocols for desired function computation and noise addition. We use oblivious transfer (OT) extensively for the multi-party computation to improve efficiency for operations such as bit-vector multiplication, oblivious random access, and arithmetic comparison. In addition, we use HyCC~\cite{buscher2018hycc}, i.e., an automated compilation tool for generating circuits for hybrid MPC protocols.

% \textbf{Thesis Outline}
% The remainder of this thesis is structured in five parts.

% In Part 1 - Preliminaries~\autoref{cha:prelim}, we discuss basic notations and theoretical background of MPC and DP. In chapter 2, we recap the background and overview of the multiparty computation. In chapter 3, we review the differential privacy theory and describe an example application for intuition.

% In Part 2 - Secure Differentially Private Mechanisms~\autoref{cha:secureDPMechanisms}, we first describe the attack when using textbook noise generation under floating-point arithmetic. Then we introduce several existing secure noise generations and differentially private mechanisms, i.e., snapping mechanism~\autoref{sec:snappingMechanism}, Integer-Scaling mechanisms~\autoref{sec:integerScalingMechanism} and discrete Gaussian mechanism~\autoref{sec:discreteGaussianmechanism}.

% In Part 3 - General Procedure for MPC-DP Protocols~\autoref{cha:ProcedureMPCDP}, we first restate the investigated research problem and describe the general procedure for realizing differentially private mechanisms under MPC. Then we review the prior works for combining MPC and DP.

% In Part 4 - Secure MPC-DP Protocols~\autoref{cha:MPCProtocolsforDifferentiallyPrivateMechanisms}, we first describe the building blocks for our MPC protocols in~\autoref{sec:MPCBuildingBlocks}. Then, we provide the MPC protocols for differentially private mechanisms (cf.~\autoref{cha:secureDPMechanisms}).

% In Part 5 - Implementation and Evaluations~\autoref{cha:evaluation}, we implement and evaluate our MPC protocols (cf.~\autoref{cha:MPCProtocolsforDifferentiallyPrivateMechanisms}).


Artificial intelligence (AI) has ushered in rapid development since 2012, where the number of software projects that rely on AI has increased significantly~\cite{clark_2015}. However, as an essential branch of AI, machine learning (ML) heavily relies on massive data analysis, posing severe privacy concerns as the individual's sensitive information in the highly centralized database may be misused. Therefore, it is crucial to provide privacy protections for the users' data. Since 2008, cryptographers have proposed many privacy-preserving ML (PPML) algorithms based on secure multiparty computation (MPC). MPC enables multiple parties to perform computations with parties' inputs securely such that only the computation result is revealed. The MPC paradigm was first proposed by Yao~\cite{Yao86} and became sufficiently efficient for practical deployment until the late 2000s.

Let us consider a typical scenario of PPML: Alice wishes to investigate if she has the genetic disorders while keeping her genomic data secret. As a service provider, Bob has trained an ML model that can predict genetic disorders given genomic data. Besides, Bob wants to keep his ML model private as his intellectual property. One unrealistic solution would be to rely on a trusted third party to analyze Alice's genetic data with Bob's ML model. However, since such a trusted third party rarely exists in practice, Alice and Bob can deploy an MPC protocol to simulate a trusted third party.

Although MPC can guarantee the users' computational privacy, an adversary can still infer users' sensitive information from the computation output. \CHANGED{Shokri et al.~\cite{shokri2017membership} showed a membership inference attack that can determine if a data record was in the model's training dataset by making an adversarial usage of ML algorithms. One solution to resist such an attack is to deploy differentially private algorithms.} The concept of differential privacy (DP) is introduced by Dwork et.al~\cite{dwork2006differential, dwork2006calibrating} that limits private information disclosure by adding calibrated noise to the revealed computation output.

To achieve both computational and output privacy, the natural approach is to combine both MPC and DP as already investigated by prior works~\cite{eigner2014differentially, pettai2015combining, byrd2020differentially}. However, to the best of our knowledge, none of them have considered the security issues of DP that arise in many practical implementations. Mironov~\cite{mironov2012significance} showed that the textbook noise generation methods could break DP due to floating-point arithmetics' finite precision and rounding effects. Our works attempt to fill this gap by providing efficient and secure MPC protocols based on the state-of-the-art MPC framework MOTION~\cite{braun2020motion}.

\textbf{Research Goal}
In this thesis, we investigate how to combine differentially private algorithms and MPC techniques under floating-point arithmetics in a secure manner. Specifically, we design novel MPC protocols for differentially private algorithms and secure noise generation methods based on works~\cite{mironov2012significance,googleDP2019,canonne2020discrete}. The basic idea is to generate discrete noise and re-scale it precisely under floating-point implementation such that the distribution of the noise \textit{really} satisfy differential privacy requirements. Besides, we aim to achieving DP and maintain the utility of the computation result by adding the minimal amount of noise required to achieve DP. We also aim at efficient MPC protocols by evaluating the practical performance of various MPC optimization techniques~\cite{braun2020motion}.

\textbf{Contributions}
We support a variety of differentilly private mechanisms such as (discrete) Laplace mechanism~\cite{chan2012privacy,ghosh2012universally,dwork2014algorithmic}, (discrete) Gaussian mechanism~\cite{dwork2014algorithmic, canonne2020discrete} and snapping mechanism~\cite{mironov2012significance} that are suitable for various applications such as, web analytics, health services.
We consider the outsourcing scenario~\cite{kamara2011secure}, i.e., the data owners first secret share their private input to multiple ($N \geq 2$) non-colluding computation parties, and the computation parties execute the MPC protocols to securely compute the desired functionality and perturb the result. We rely on the MOTION framework~\cite{braun2020motion} that supports full-threshold security, which means that the computation result is secure as long as one computation party is honest. Therefore, the computation parties can jointly generate the shares of a publicly unknown noise with the same magnitude as the noise generated by a single trusted server.
This guarantees that the computation result is perturbed with minimal amount of noise required to achieve DP.
To find the most efficient implementation of the arithmetic operations in MPC, we explore both fixed-point and floating-point arithmetic and implement them in the binary circuit-based and arithmetic sharing approaches.
In constructing MPC protocols, we use Single Instruction Multiple Data (SIMD) instructions to eliminate the independent iterations in the sampling algorithms and improve the performance.

% \TODO{describe novel MPC techniques...}

\textbf{Thesis Outline}
% \TODO{add after revision}
This thesis is organized as follows:
Chapter 2 give the preliminaries on the concept of secure multiparty computation and differential privacy with motivating examples and formal definitions.
Chapter 3 describes the details of the differentially private mechanisms we wish to realize in MPC and our modifications.
Chapter 4 provides the procedure to combine MPC protocols and differentially private mechanisms, necessary MPC building blocks, and our MPC protocols for differentially private mechanisms.
Chapter 5 evaluates the performance of our MPC protocols.
\TODO{add after revision}
% The remainder of this thesis is structured in three parts.
% In Part 1 - Preliminaries (ref), we discuss basic notations and theoretical background of MPC and DP. In chapter 2 we recap the background and overview of the multiparty computation. In chapter 3, we review the differential privacy theory and describe an example application for intuition. 

% In Part 2 - Secure Noise Generation, we first describe the attack when using textbook noise generation under floating-point implementation. Then we introduce several secure noise generations under floating-point representation.

% In Part 3 - MPC-DP Protocols, we first explain the advantages and difficulties of combining MPC and DP, and then propose the general MPC-DP framework in chapter x. In chapter x and x, we provide the construction and optimization of MPC protocols for noise generation. In chapter x, we implement the MPC protocols and evaluate the MPC-DP framework with typical machine learning problems. 
