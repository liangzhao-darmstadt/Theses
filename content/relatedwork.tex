\chapter{Related Work}
\label{cha:RelatedWork}

\section{Distributed Differential Privacy (DDP)}
\label{sec:DistributedDifferentialPrivacy}
% To achieve differential privacy (DP) in a federated learning scenario, either a central trusted server (centralized model) is assumed to perform perturbation to the aggregated result, or each client perturbs its data (local model) before sending it to the central server. However, in the centralized model, the trusted server is responsible for security and privacy and becomes the single point of failure for the entire system. In the decentralized model, when each client perturbs its data to guarantee privacy, the noise in the aggregated result is superﬂuous and may decrease the utility.
% Several solutions that combine differential privacy and secure multiparty computation (MPC) have been proposed to guarantee privacy and utility. The first key point to solve the problem is deploying MPC instead of the strong assumption of a trusted server. The second point is to reduce redundant noise by ensuring all clients perturbs the data collaboratively rather than independently.

The fundamental idea of differential privacy~\cite{dwork2006differential} is to perturb the query on a database such that influence of each individual record in the database is bounded. The original definition of \differentialprivacy assumes the existence of a centralized and trusted server that manages the database and process the queries. Subsequent works~\cite{dwork2006our} extends \differentialprivacy to a distributed setting, where the central server is replaced by several mutually distrustful and potentially malicious computation parties. To the best of our knowledge, Dwork et al.~\cite{dwork2006our} was the first to consider deploying malicious \smpc to aggregate and perturb data with the shares of random noise. Generally, the works that attemepes to realizied \ddp can be categorized into two groups: central \differentialprivacy model and local \differentialprivacy model. In the central \differentialprivacy model, a trusted, central server responsible for computing the aggregate statistics and perturbation, is simulated by several semi-honest (or malicious) computation parties with \smpc. It is typically assumed that the majority of computation parties are not colluding. However, \smpc incurs high computation and communication overhead that reduces the efficiency and scalability. In the local \differentialprivacy model, the server is not trusted anymore. The users applies randomness to privatized their data before sending to the server. Therefore, the accuracy of the aggregate statistics is limited as the randomization is applied multiple times. Both models face series of open challenges and we discuss the details of them below.

\subsection{Local DP Model}
\label{subsec:LocallDPModel}
The existing solution to local \differentialprivacy model~\cite{rastogi2010differentially,Elaine2011Privacy,acs2011have, chan2012privacy,bindschaedler2017achieving,shi2017distributed,truex2019hybrid} relied on homomorphic encryption, \smpc and the infinite divisibility of certain probability distribution (e.g., Laplace distribution~\cite{kotz2001laplace} and Gaussian distribution). Specifically, each user perturbs their data independently and encrypts it with homomorphic encryption scheme such that the server can aggregate the encrypted data and only reveal the noisy aggregated result.
Instead of using homomorphic encryption, other works~\cite{byrd2020differentially,ghazi2021differentially,balle2020private} had the users to mask the local perturbed data with additional noise and send the masked data to the server. After the aggregation of the server, the additional noise is canceled out and the noisy result that satisfied \differentialprivacy is revealed.
However, the existing works of local \differentialprivacy model faces two major challenges. The first challenge is that the collusion users can substract their noise term from the revealed result and reduce the \differentialprivacy-guarantee. Therefore, in order to achieve the required \differentialprivacy guarantee, each user has to add a larger amount of noise, that leads a reduced utility of the aggregated result.
The second challenge is that the users have to pay significant amount of computation effort, that makes the local \differentialprivacy model less practical for devices that has limited computation power.


\subsection{Central DP Model}
\label{subsec:CentralDPModel}

For the central \differentialprivacy model, prior works~\cite{dwork2006our, eigner2014differentially,wu2016inherit,jayaraman2018distributed,knott2021crypten,yuan2021practical,eriguchi2021efficient} porposed variety of methods to satisfy \differentialprivacy by generating distributed noise in \smpc.
Dwork et al.~\cite{dwork2006our} supported noise from two distributions : Gaussian distribution (approximated with binomial distribution), discrete Laplace distribution (approximated with Possion distribution).
To satisfy $\left(\varepsilon ,\delta \right) $-\differentialprivacy, it needs to process $n\geq 64 \log_2{\left(2/\delta \right) }/\varepsilon ^2$ (e.g., $\varepsilon =0.01 \text{, }\delta=0.0001\Rightarrow n\approx 2^{23}$ ) uniform random bits in \smpc to generate binomial noise, that would leads to high \smpc overhead.
For discrete Laplace noise, the protocol requires securely evaluating a circuit in \smpc to generating biased bits. However, the evaluation of the circuit fails with non-zero probability and requires multiple iterations to make the failure probability negligible.
Eigner et al.~\cite{eigner2014differentially} proposed an architecture called PrivaDA, that combined \differentialprivacy and \smpc, and generated Laplace noise and discrete Laplace noise in \smpc protocols. However, the generated Laplace noise suffers from the floating-point attack~\cite{mironov2012significance}. The discrete Laplace noise is susceptible to similar floating-point attack because its generation procedure is similar to the Laplace noise.
Wu et al.~\cite{wu2016inherit} described methods for generating Bernoulli noise, Laplace noise, and Gaussian noise in \smpc setting. The Laplace noise is generated basd on the central limit theory~\cite[Example 10.3.2]{athreya2006measure}, i.e., the aggregation of $n$ of Bernoulli random variable $Bern\left(0.5\right)$ approximates a normal random variable $\mathcal{N} \left(0,\frac{1}{4}\right)$ because of ($\sqrt{n}\left(\frac{\sum_{i = 1}^{n}  Bern\left(0.5\right) }{n}-\mu\right) \approx \mathcal{N} \left(0,\frac{1}{4}\right)   $). However, the central limit theory holds when $n \to \infty $, and there is no discussion about whether the choice of $n$ would affect \differentialprivacy guarantee in the work of Wu et al.~\cite{wu2016inherit}.

Jayaraman et al.~\cite{jayaraman2018distributed}, Knott et al.~\cite{knott2021crypten} and Yuan et al.~\cite{yuan2021practical} presented distributed learning approaches that combine \smpc and \differentialprivacy by generating distributed Laplace noise and Gaussian noise with \smpc protocols. The protocols for Laplace noise are similar to the work of Eigner et al.~\cite{eigner2014differentially}, and the protocol for Gaussian noise are all based on the Box-Muller sampling algorithm~\cite{box1958note}. However, Jin et al.~\cite{jin2022we} had demonetrated an floating-point attack against the Box-Muller method.

Eriguchi et al.~\cite{eriguchi2021efficient} provided \smpc-based protocols to generate two types of noise: \fdl noise and binomial noise. In contrast to discrete Laplace distribution that can sample arbitrarily large integers with low probability, \fdl can only generate integers in a given range $\left[-N,N\right] $. The protocol for binomial noise deploys pseudorandom secret-sharing~\cite{cramer2005share} for generating shares of uniform random variables non-interactively and use the binomial mechanism~\cite{agarwal2018cpsgd} to satisfy \differentialprivacy guarantee. However, the binomial mechanism only satisfy computational differential privacy~\cite{mironov2009computational}, that is an relaxation of the standard differential privacy definintion~\cite{dwork2014algorithmic} and only secure against computational bounded adversary.

Our work provides an alternative solution to the central \differentialprivacy model by \textit{securely} generating distributed noise that are not affected by the attacks~\cite{mironov2012significance,jin2022we}.


% ??? combine floating-point with fixed-point
% \TODO{literature about floating-point and fixed-point MPC protocols}
\section{Arithmetic Operations in SMPC}
\label{ArithmeticOperationsinSMPC}
% This work is built upon the MOTION~\cite{braun2022motion} framework that supports Arithmetic Sharing, Boolean sharing with \gmw and Yao sharing with BMR.

Generally, most \smpc protocols that support arithemtic operations in \smpc are based on binary circuit approach or \lsss. In binary circuit based approach, the arithmetic operations is represented as a Boolean circuit and evaluated with Yao's Garbled circuit protocol~\cite{yao1986generate} (\bmr~\cite{beaver1990round} for multi-party setting) or Boolean \gmw protocol~\cite{goldreich1987play}.
By contrast, in the \lsss-based approach~\cite{chaum1988multiparty,ben1988completeness}, the parties divide their secret values into shares over a field $\mathbb{F} _q$ (or a ring $\mathbb{Z} _{2^{\ell}}$) and send it to each of the parties. Next, we explain the \smpc protocols for arithemtic operations of these two types in details.


\subsection{LSSS-Based SMPC}
\label{subsec:LSSS-BasedSMPC}
In order to guarantee the high efficiency of the \smpc protocols, much prior works~\cite{catrina2010secure,liedel2012secure,hemenway2016high,aly2019benchmarking,lu2020faster} deployed fixed-point arithmetic to represent real number operations.
Catrina and Saxena~\cite{catrina2010secure} built a series of fixed-point operations (e.g., additioin, subtraction, multiplication and division) by representing a fixed-point $x = \overline{x}\cdot  2^{-f}$, where $\overline{x}$ is an integer in field $\mathbb{F} _q$ and $f$ is the length of oth fraction bits.
The works~\cite{liedel2012secure,hemenway2016high,aly2019benchmarking,lu2020faster} proposed protocols for fixed-point operations such as exponential, square root, natural logarithm, and trigonometric functions with polynomial approximation~\cite{hart1978computer} or Goldschmidt approximation~\cite{markstein2004software}.

Another line of works~\cite{aliasgari2012secure,krips2014hybrid,kamm2015secure,rathee2022secfloat} focused on floating-point operations.

Aliasgari et al.~\cite{aliasgari2012secure} used a quadruple $\left(v, p, z, s\right) $ to represent the floating-point number $u= \left(1-2s\right) \cdot \left(1-z\right) \cdot v \cdot 2^p$, where $v$ (mantissa), $p$ (exponent), $z$ (zero bit), and $s \text{ (sign bit)}\in \mathbb{F} _q$. Aliasgari et al.~\cite{aliasgari2012secure} also provided \smpc protocols for operations such as addition, subtraction, multiplication, divisibility, square root, logarithm, and expoentiation.
The subsequent works~\cite{krips2014hybrid,kamm2015secure,rathee2022secfloat} applied similar representation form of the floating-point numbers.

Truex et al.~\cite{truex2019hybrid} proposed a hybrid method combing fixed-point and floating-point arithmetic, i.e., representing the mantissa of a floating-point number as fixed-point number, and used \lsss-based fixed-point arithmetic when the mantissa is involved in the floating-point arithmetic. However, the fixed-point arithmetic is prone to overflow or underflow that requires additionial \smpc protocols to fixed the computation result that decrease the overall protocol performance.

Kamm and Willemson et al.~\cite{kamm2015secure} provided \smpc protocols for square root, natural exponentiation, and error function approximated with Taylor series expansion or Chebyshev polynomials.
% (ref. Optimizing MPC for Robust and Scalable Integer and Floating-Point Arithmetic) provide optimization for (hybrid model of ....) by parallelizing the polynomial approximation, eliminate branching by representing negative integer using two's complementation, etw.

Rathee et al.~\cite{rathee2022secfloat} built a precise and efficient 32-bit floating-point operation library (SecFloat) for secure two-party computation. One highlight is the use of the mixed-bitwidth computation technique, i.e., use low bitwidth to represent numbers as much as possible. The conversion operations between different bitwidth are performed with specialized zero-extension and truncation \twopc protocols.
The second highlight is the use of low-degree polynomials to improve accuracy and efficiency.
One common method to compute function like $log_{2}x$ is polynomial approximation, where high-degree polynomials yields more accurate result but incur more computation effort. Rathee et al.~\cite{rathee2022secfloat} replaced the high-degree polynomials with low-degree piecewise polynomials without decrease accuracy. In specifically, for input $x\in \left(a,b\right) $, they approximated $log_2 x$ using different low-degree polynomials for $k$ subintervals ($\left(a, a_1\right) $, $\left(a_1, a_2\right)  $,$\ldots$, $\left(a_{k-1}, b\right) $). To determine the active interval of $x$, they deployed the \lut protocol~\cite{dessouky2017pushing} to compute the correct polynomial coefficients.
To explore if efficiency of SecFloat~\cite{rathee2022secfloat} still preserves in multi-party setting, we implement its building blocks (conversion operations between low-bitwidth and high-bitwidth, multi-party lookup table protocol~\cite{keller2017faster}, MSNZB~\cite{rathee2021sirnn}) in the MITION~\cite{braun2022motion} framework. After benchmarking (cf.~\autoref{runtimes_secfloat}), we found the benefit brought by mixed-bitwidth becomes negligible when extending it to a multi-party setting. The reason is as follows:
\begin{enumerate}
    \item The conversion operations between low-bitwidth and high-bitwidth in SecFloat rely on \twopc comparison protocol based on \ot, and it can not be directly extended to multi-party setting.
    \item In the two-party setting, when we take the value of two $\ell$-bit arithmetic shares $\left\langle a\right\rangle^A_0 $, $\left\langle a\right\rangle^A_1$ as plaintext value and compute the addition result, we need an $\ell+1$-bit integer $a =\left\langle a\right\rangle^A_0 +\left\langle a\right\rangle^A_1 $ to hold the addition result without overflow. The most significant bit of $a$ is used during the conversion operation. For $N\geq 3$ parties, the addition result of $N$ $\ell$-bit arithmetic value needs a $\left\lceil \log_2{N}\right\rceil +l$-bit integer to hold. The $\left\lceil \log_2{N}\right\rceil$ most significant bits are used for the conversion. As the number of parties grows, the complexity of conversion operations also increases.
\end{enumerate}

Protocol $MSNZB\left(\left\langle x\right\rangle^A\right) $~\cite{aliasgari2012secure,rathee2021sirnn} computes the most significant non-zero bit index of the input $\left\langle x\right\rangle^A \in \mathbb{Z} _{2^{\ell}}$ in arithmetic share.
We implement two types of $MSNZB$~\cite{aliasgari2012secure,rathee2021sirnn} protocols in MOTION~\cite{braun2022motion} and evaluate the performance.

$MSNZB$~\cite{aliasgari2012secure} used operations such as bit-decomposition, Boolean sharing to arithmetic sharing conversion and arithemtic sharing addition.
By contrast, $MSNZB$~\cite{rathee2021sirnn} first decomposed the input $\left\langle x\right\rangle^A \in \mathbb{Z} _{2^{\ell}}$ into $\frac{\ell}{8}$ low-bitwidth arithmetic shares $\left\langle x_1\right\rangle^A$, $\left\langle x_2\right\rangle^A$, $\ldots$,  $\left\langle x_{\ell/8}\right\rangle^A\in \mathbb{Z} _{2^{{8}}} $. Then, each low-bitwidth arithmetic share is used as a input to the lookup table protocol to compute $MSNZB\left(\left\langle x_1\right\rangle^A\right) $, $\ldots$, $MSNZB\left(\left\langle x_{\ell/8}\right\rangle^A\right) $. Finally, $MSNZB\left(\left\langle x_1\right\rangle^A\right) $, $\ldots$, $MSNZB\left(\left\langle x_{\ell/8}\right\rangle^A\right) $ were combined together to compute $MSNZB\left(\left\langle x\right\rangle^A\right) $. We can see in \autoref{tab:runtimes_secfloat} that the use of mixed-bitwidth and lookup table does not bring efficiency improvement in the LAN (10Gbit/s Bandwidth, 1ms RTT) and WAN (100Mbit/s Bandwidth, 100ms RTT) networks. Details of benchmark environment are in~\autoref{cha:evaluation}.

\begin{table}[H]
    \caption{
        Online run-times in milliseconds (ms) for operation MSNZB for the GMW (A). We take the average over 10 protocol runs in the LAN and WAN environments.
    }
    \label{tab:runtimes_secfloat}
    % \small
    \centering
    \nprounddigits{1} % remove fractional digits in this table
    \rowcolors{1}{gray!25}{white}
    % \resizebox{\columnwidth}{!}{
    \begin{tabular}{ l r r r r r r r r r r r}
        \toprule
        \hiderowcolors                          & \multicolumn{2}{c}{LAN} &        & \multicolumn{2}{c}{WAN}                         \\
        \cmidrule{2-3} \cmidrule{5-6} Operation &
        $N{=}3$                                 & $N{=}5$                 &        &
        $N{=}3$                                 & $N{=}5$                                                                            \\ \showrowcolors
        \midrule
        $MSNZB$~\cite{aliasgari2012secure}      & 18.41                   & 80.12  &                         & 886.06    & 1\,036.23 \\
        $MSNZB$~\cite{rathee2022secfloat}       & 359.76                  & 567.14 &                         & 5\,436.82 & 6\,355.90 \\
        \bottomrule
    \end{tabular}
    % }
\end{table}
\FloatBarrier


\subsection{Binary Circuit Based SMPC}
\label{subsec:BinaryCircuitBasedSMPC}

The binary circuits are typically composed of $\operatorname{XOR}$, $\operatorname{NOT}$ and $\operatorname{AND}$ gates, where the $\operatorname{AND}$ gates cause the major cost. Therefore, the binary circuits should be optimized based on the cost metric of \smpc protocols. A common method to generate low $\operatorname{AND}$-depth and low $\operatorname{AND}$-size binary circuit is to use CBMC-GC~\cite{buscher2016compiling} circuit compiler that derives circuit design with C program. Pullonen and Siim~\cite{pullonen2015combining} used CBMC-GC~\cite{buscher2016compiling} circuit compiler to generate size-optimized circuit for IEEE 754 floating-point operations with C library~\cite{BerkelySoftFloat,musllibc}. Archer et al.~\cite{archer2021cost} deployed use CBMC-GC~\cite{buscher2016compiling} to generate depth-optimized circuit for IEEE 754 floating-point operations. In this works, we also use CBMC-GC~\cite{archer2021cost} to generate depth-optimized circuit and size-optimized circuits for arithemtic operations with different C librarys~\cite{BerkelySoftFloat,musllibc} or available optimized circuits from work~\cite{demmler2015aby}.


% However, we find that SecFloat can't be extended to $N$-party computations ($N\geq 3$) while preserving its efficiency. First, SecFloat relies heavily on the Oblivious Transfer techniques (ref. crytpflow) for mix-bitwidth and $LUT$ operationsm which is not available in multi-party computations. To verify this, we implement the $MSNZB$ (most significant non-zero bit index) protocol deployed in SecFloat using the idea of mix-bitwidth and $LUT$ (ref. fast LUT) in MOTION framework, and compare it with a another implementation of $MSNZB$ that use Boolean GMW operation and share conversion.



% Pullonen and Siim~\cite{pullonen2015combining} presented another hybrid protocol that used Yao's Garbled Circuit protocol~\cite{yao1986generate} for bit-level operations and \lsss-based


% \textbf{MPC Protocols for Floating-Point Arithmetic}
% There are prior works that focus on floating-point arithmetic MPC protocols.
% (ref. Secure Floating-Point Arithmetic and Private Satellite Collision Analysis) provides AGMW based floating-point MPC protocols and using polynomial approximation for $exp$, $sqrt$, etw.


% (ref. Combining Secret Sharing and Garbled Circuits for Efficient Private IEEE 754 Floating-Point Computations) provides a hybrid protocol for 2-party floating-point arithmetic that convert bgmw sharing to Yao's sharing and evaluate arithmetic operation as Garbled circuits protocols.





% After the benchmarking, we found that for MPC frameworks that support multiparty computations, the efficiency benefit brought by mix-bitwidth would be negligible as $N$ increases. ??? zero-extension, LUT multiparty complexity analysis.



% (ref. The The Cost of IEEE Arithmetic in Secure Computation) implement LSSS-based and binary circuit-based floating-point arithmetic MPC protocols and compare their performance. In their benchmarking result, the LSSS-based floating-point operation is about $10-100x$ faster than binary circuit-based floating-point operation. However, in our implementation, the binary circuit-based floating-point operation is $5-10x$ faster than LSSS-based floating-based without SIMD and can be up to $1000x$ faster than LSSS-based floating-point operation when amortized over SIMD=1000.

% \textbf{MPC Protocols for Fixed-Point Arithmetic}
% (ref. High-precision Secure Computation of Satellite Collision Probabilities) provides methods for 2-party fixed-point arithmetic by combine AGMW and BGMW, i.e., using AGMW for integer addition and multiplication using AGMW and BGMW for integer comparison, shifting, $exp$, etw.

% (ref.  Benchmarking Privacy Preserving Scientific Operations) provides AGMW based fixed-point arithmetic.

% (ref. Round-Efﬁcient Protocols for Secure Multiparty Fixed-Point Arithmetic) agmw fixed-point.






